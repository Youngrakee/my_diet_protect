import os
import json
import requests
import base64
from datetime import datetime
from dotenv import load_dotenv
import operator
from typing import TypedDict, Annotated, List

# OpenAI ë° LangChain ê´€ë ¨ ì„í¬íŠ¸
from openai import OpenAI
from langchain_openai import ChatOpenAI
from langchain_core.messages import SystemMessage, HumanMessage, AIMessage, ToolMessage
from langchain_core.tools import tool
from langgraph.graph import StateGraph, END

load_dotenv()

OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
KAKAO_API_KEY = os.getenv("KAKAO_API_KEY")

# ì¼ë°˜ OpenAI í´ë¼ì´ì–¸íŠ¸ (analyze_foodìš©)
client = OpenAI(api_key=OPENAI_API_KEY)

# =========================================================
# 1. ë„êµ¬(Tool) ì •ì˜ - LangChain @tool ë°ì½”ë ˆì´í„° ì‚¬ìš©
# =========================================================
@tool
def search_restaurants(location: str, menu_keyword: str):
    """
    íŠ¹ì • ì§€ì—­ì˜ ì‹ë‹¹ì´ë‚˜ ë©”ë‰´ë¥¼ ì¹´ì¹´ì˜¤ë§µì—ì„œ ê²€ìƒ‰í•©ë‹ˆë‹¤.
    location: ê²€ìƒ‰í•  ì§€ì—­ (ì˜ˆ: ê°•ë‚¨ì—­, í™ëŒ€)
    menu_keyword: ê²€ìƒ‰í•  ë©”ë‰´ (ì˜ˆ: ìƒëŸ¬ë“œ, í•œì‹)
    """
    if not KAKAO_API_KEY:
        return "Error: ì¹´ì¹´ì˜¤ API í‚¤ê°€ ì—†ìŠµë‹ˆë‹¤."

    url = "https://dapi.kakao.com/v2/local/search/keyword.json"
    headers = {"Authorization": f"KakaoAK {KAKAO_API_KEY}"}
    query = f"{location} {menu_keyword}".strip()
    
    try:
        response = requests.get(url, headers=headers, params={"query": query, "size": 3})
        if response.status_code == 200:
            docs = response.json().get('documents', [])
            if not docs:
                return "NOT_FOUND: ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤."
            
            # AIê°€ ì½ê¸° ì¢‹ê²Œ ë¬¸ìì—´ë¡œ ìš”ì•½í•´ì„œ ë°˜í™˜
            results = []
            for doc in docs:
                results.append(f"ì´ë¦„: {doc['place_name']}, URL: {doc['place_url']}, ì¹´í…Œê³ ë¦¬: {doc['category_name']}")
            return "\n".join(results)
        else:
            return f"API í˜¸ì¶œ ì—ëŸ¬: {response.status_code}"
    except Exception as e:
        return f"ê²€ìƒ‰ ì¤‘ ì—ëŸ¬ ë°œìƒ: {e}"

# =========================================================
# 2. ì‹ë‹¨ ë¶„ì„ í•¨ìˆ˜ (ê¸°ì¡´ ì½”ë“œ ìœ ì§€)
# =========================================================
ANALYSIS_PROMPT = """
ë‹¹ì‹ ì€ ë‹¹ë‡¨/ë‹¤ì´ì–´íŠ¸ ì „ë¬¸ ì˜ì–‘ì‚¬ì…ë‹ˆë‹¤. ì…ë ¥ëœ ìŒì‹ì„ ë¶„ì„í•˜ì—¬ JSONìœ¼ë¡œ ë°˜í™˜í•˜ì„¸ìš”.(í•œêµ­ì–´ë¡œ ì„¤ëª…í• ê²ƒ)
í¬ë§·: {"food_name": "...", "blood_sugar_level": "...", "summary": "...", "action_guide": "...", "alternatives": "..."}
"""

def analyze_food(text_input: str = None, image_bytes: bytes = None, user_profile: dict = None):
    messages = [{"role": "system", "content": ANALYSIS_PROMPT}]
    
    if user_profile:
        messages[0]["content"] += f"\n[ì‚¬ìš©ì ì •ë³´] {user_profile}"

    user_content = []
    if text_input: user_content.append({"type": "text", "text": text_input})
    if image_bytes:
        b64_img = base64.b64encode(image_bytes).decode('utf-8')
        user_content.append({"type": "image_url", "image_url": {"url": f"data:image/jpeg;base64,{b64_img}"}})
    
    messages.append({"role": "user", "content": user_content})

    try:
        res = client.chat.completions.create(model="gpt-4o", messages=messages, max_tokens=600)
        content = res.choices[0].message.content.replace("```json", "").replace("```", "").strip()
        return json.loads(content)
    except Exception as e:
        print(f"Analyze Error: {e}")
        return {"food_name": "Error", "blood_sugar_level": "ì•Œ ìˆ˜ ì—†ìŒ", "summary": "ë¶„ì„ ì‹¤íŒ¨"}

# =========================================================
# 3. LangGraph ìƒíƒœ ë° ë…¸ë“œ ì •ì˜ 
# =========================================================
class AgentState(TypedDict):
    messages: Annotated[List, operator.add]
    user_profile: dict
    current_time: str

# LangChain LLM ì´ˆê¸°í™”
llm = ChatOpenAI(model="gpt-4o", temperature=0.7)
llm_with_tools = llm.bind_tools([search_restaurants])

def chatbot_node(state: AgentState):
    """ë©”ì¸ ì±—ë´‡ ë…¸ë“œ"""
    profile = state["user_profile"]
    now = state["current_time"]
    
    system_msg = f"""
    ë‹¹ì‹ ì€ ì„¼ìŠ¤ ìˆê³  í˜„ì‹¤ì ì¸ AI ì˜ì–‘ì‚¬ 'ì˜¤ëŠ˜ë­ë¨¹ì§€.ai'ì…ë‹ˆë‹¤.
    í˜„ì¬ ì‹œê°„: {now}
    ì‚¬ìš©ì ì •ë³´: [ë‹¹ë‡¨: {profile.get('diabetes_type', 'ì •ë³´ ì—†ìŒ')}, ëª©í‘œ: {profile.get('health_goal', 'ê±´ê°• ê´€ë¦¬')}]
    
    [Step 1: ì‹œê°„ëŒ€ ë° ì˜ë„ íŒŒì•… (ìš°ì„ ìˆœìœ„ 1ìœ„)]
    1. **ì‚¬ìš©ìì˜ ë°œí™”(ì˜ë„)**ë¥¼ ìµœìš°ì„ ìœ¼ë¡œ ë”°ë¥´ì„¸ìš”. (ì˜ˆ: ë‚® 12ì‹œë¼ë„ "ì•¼ì‹ ì¶”ì²œí•´ì¤˜"ë¼ë©´ ì•¼ì‹ ê·œì¹™ ì ìš©)
    2. ì–¸ê¸‰ì´ ì—†ìœ¼ë©´ [í˜„ì¬ ì‹œê°„]ì„ ê¸°ì¤€ìœ¼ë¡œ íŒë‹¨í•˜ì„¸ìš”.
    
    [Step 2: ë©”ë‰´ ì„ ì • ê·œì¹™ (ìƒëŸ¬ë“œ ë´‡ ê¸ˆì§€!)]
    - **ì•„ì¹¨**: ë‡Œë¥¼ ê¹¨ìš°ëŠ” ê°€ë²¼ìš´ íƒ„ìˆ˜í™”ë¬¼+ë‹¨ë°±ì§ˆ (ê·¸ë¦­ìš”ê±°íŠ¸, ì˜¤íŠ¸ë°€, ìƒŒë“œìœ„ì¹˜).
    - **ì ì‹¬/ì €ë… (ì‹ì‚¬ ì‹œê°„)**: 
       ğŸ‘‰ **ë¬´ì¡°ê±´ ìƒëŸ¬ë“œë§Œ ì¶”ì²œí•˜ì§€ ë§ˆì„¸ìš”! ë§›ìˆëŠ” ìŒì‹ì„ ì›í•©ë‹ˆë‹¤.**
       - í•œì‹: ë¹„ë¹”ë°¥(í˜„ë¯¸), ìƒì„ êµ¬ì´ ì •ì‹, ìŒˆë°¥, ìˆœë‘ë¶€ì°Œê°œ, ì¶”ì–´íƒ•, ìƒ¤ë¸Œìƒ¤ë¸Œ.
       - ì¼ì‹: íšŒë®ë°¥, ì´ˆë°¥(ë°¥ ì ê²Œ), ë§‘ì€ ì§€ë¦¬íƒ•.
       - ê³ ê¸°: ì˜¤ë¦¬ê³ ê¸°, ë³´ìŒˆ/ìˆ˜ìœ¡, ë‹­ë°±ìˆ™.
       - *ì§ì „ ë¼ë‹ˆê°€ ë©´/ë¹µì´ì—ˆë‹¤ë©´ í•œì‹ ì •ì‹ì„ ìš°ì„  ì¶”ì²œí•˜ì„¸ìš”.*
    - **ì•¼ì‹/ì‹¬ì•¼ (21ì‹œ ì´í›„)**:
       ğŸ‘‰ **ì—¬ê¸°ì„œëŠ” 'ì‹ì‚¬ ë©”ë‰´' ì¶”ì²œì„ ë©ˆì¶”ì„¸ìš”.**
       - ğŸš¨ ê²½ê³ : ë¹„ë¹”ë°¥, êµ­ë°¥, ì •ì‹ ë“±ì€ í˜ˆë‹¹/ìˆ˜ë©´ì— ì¹˜ëª…ì ì…ë‹ˆë‹¤. ì ˆëŒ€ ì¶”ì²œí•˜ì§€ ë§ˆì„¸ìš”.
       - ì¶”ì²œ: ë”°ëœ»í•œ ìš°ìœ /ë‘ìœ , ì—°ë‘ë¶€, ì˜¤ì´/ë‹¹ê·¼ ìŠ¤í‹±, ì‚¶ì€ ê³„ë€, í† ë§ˆí† .

    [Step 3: ê²€ìƒ‰ í‚¤ì›Œë“œ ì„ ì • ë° ë„êµ¬ ì‚¬ìš©]
    1. ì‚¬ìš©ìê°€ ì¥ì†Œë¥¼ ë§í•˜ë©´ `search_restaurants` ë„êµ¬ë¥¼ ì‹¤í–‰í•˜ì„¸ìš”.
    2. **í‚¤ì›Œë“œ ì„ ì • ì£¼ì˜**: ê²€ìƒ‰ ê²°ê³¼ê°€ ì˜ ë‚˜ì˜¤ë„ë¡ **ìƒìœ„ ì¹´í…Œê³ ë¦¬**ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”.
       - (X) 'ì™„ì •ì—­ ì—°ì–´ ìŠ¤í…Œì´í¬' -> (O) 'ì™„ì •ì—­ ìƒì„ êµ¬ì´' ë˜ëŠ” 'ì™„ì •ì—­ ì¼ì‹'
       - (X) 'ê°•ë‚¨ì—­ ê³¤ì•½ ë–¡ë³¶ì´' -> (O) 'ê°•ë‚¨ì—­ í‚¤í† ' ë˜ëŠ” 'ê°•ë‚¨ì—­ ìƒëŸ¬ë“œ'
    3. ì•¼ì‹ ì§ˆë¬¸ì—ëŠ” ì‹ë‹¹ ê²€ìƒ‰ë³´ë‹¤ëŠ” 'í¸ì˜ì  ë©”ë‰´'ë‚˜ 'ì§‘ì—ì„œ ë¨¹ì„ ë©”ë‰´'ë¥¼ ì œì•ˆí•˜ëŠ” ê²Œ ë‚˜ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
    
    [Step 4: ì˜ˆì™¸ ì²˜ë¦¬]
    - ë„êµ¬ ê²°ê³¼ê°€ "NOT_FOUND"ë¼ë©´ ì†”ì§í•˜ê²Œ ë§í•˜ê³ , ì£¼ë³€ì— ìˆì„ ë²•í•œ ë‹¤ë¥¸ ê±´ê°• ë©”ë‰´(ì˜ˆ: ì„œë¸Œì›¨ì´, êµ­ë°¥ì§‘ ë“±)ë¥¼ ëŒ€ì•ˆìœ¼ë¡œ ì œì‹œí•˜ì„¸ìš”.
    - ë„êµ¬ ê²°ê³¼ì˜ URLì„ `[ì‹ë‹¹ëª…](URL)` í˜•íƒœë¡œ ë§í¬ë¥¼ ê±°ì„¸ìš”.
    """
    
    messages = [SystemMessage(content=system_msg)] + state["messages"]
    response = llm_with_tools.invoke(messages)
    return {"messages": [response]}

def tool_node(state: AgentState):
    """ë„êµ¬ ì‹¤í–‰ ë…¸ë“œ"""
    last_message = state["messages"][-1]
    if not last_message.tool_calls:
        return {}

    results = []
    for tool_call in last_message.tool_calls:
        if tool_call["name"] == "search_restaurants":
            print(f"ğŸ› ï¸ [LangGraph] ë„êµ¬ ì‹¤í–‰: {tool_call['args']}")
            res = search_restaurants.invoke(tool_call["args"])
            results.append(ToolMessage(tool_call_id=tool_call["id"], content=str(res)))
            
    return {"messages": results}

def safety_check_node(state: AgentState):
    """(Self-Correction) ë‹¹ë‡¨ í™˜ì ì•ˆì „ ê²€ì‚¬ ë…¸ë“œ"""
    last_message = state["messages"][-1]
    profile = state["user_profile"]
    
    # íˆ´ í˜¸ì¶œì´ë‚˜ ì‹œìŠ¤í…œ ë©”ì‹œì§€ë©´ ê±´ë„ˆëœ€
    if not isinstance(last_message, AIMessage) or last_message.tool_calls:
        return {}

    # ë‹¹ë‡¨ í™˜ìì¼ ë•Œë§Œ ì—„ê²©í•˜ê²Œ ê²€ì‚¬ (Self-Correction ë™ì‘)
    if "ë‹¹ë‡¨" in str(profile.get('diabetes_type')):
        checker_llm = ChatOpenAI(model="gpt-4o", temperature=0)
        check_prompt = f"""
        ì‚¬ìš©ìëŠ” '{profile.get('diabetes_type')}' í™˜ìì…ë‹ˆë‹¤.
        AI ë‹µë³€: "{last_message.content}"
        
        ì´ ë‹µë³€ì´ ê³ ë‹¹ë¶„/ê³ íƒ„ìˆ˜í™”ë¬¼(ë¹„ë¹”ë°¥, êµ­ë°¥, ì§œì¥ë©´, ì¼€ì´í¬ ë“±)ì„ 'ì•¼ì‹'ìœ¼ë¡œ ì¶”ì²œí•˜ê±°ë‚˜,
        í˜ˆë‹¹ì— ì¹˜ëª…ì ì¸ ìŒì‹ì„ 'ê°•ë ¥ ì¶”ì²œ'í•˜ê³  ìˆë‹¤ë©´ "DANGER: [ì´ìœ ]"ë¥¼ ì¶œë ¥í•˜ì„¸ìš”.
        ì•ˆì „í•˜ë‹¤ë©´ "SAFE"ë¥¼ ì¶œë ¥í•˜ì„¸ìš”.
        """
        check_res = checker_llm.invoke([HumanMessage(content=check_prompt)])
        
        if check_res.content.startswith("DANGER"):
            print(f"ğŸš¨ [LangGraph] ì•ˆì „ ê²€ì‚¬ ì‹¤íŒ¨: {check_res.content}")
            correction_msg = f"ì ê¹! ì‚¬ìš©ìëŠ” ë‹¹ë‡¨ í™˜ìì•¼. ë°©ê¸ˆ ì¶”ì²œì€ ìœ„í—˜í•´. ({check_res.content}) ë‚´ìš©ì„ ë°˜ì˜í•´ì„œ ë” ì•ˆì „í•œ ë©”ë‰´ë¡œ ë‹¤ì‹œ ëŒ€ë‹µí•´."
            return {"messages": [HumanMessage(content=correction_msg, name="safety_guard")]}
            
    return {}

# =========================================================
# 4. ê·¸ë˜í”„ êµ¬ì„± (Workflow)
# =========================================================
workflow = StateGraph(AgentState)

workflow.add_node("chatbot", chatbot_node)
workflow.add_node("tools", tool_node)
workflow.add_node("safety_check", safety_check_node)

workflow.set_entry_point("chatbot")

def route_tools(state: AgentState):
    if state["messages"][-1].tool_calls:
        return "tools"
    return "safety_check"

workflow.add_conditional_edges("chatbot", route_tools, {"tools": "tools", "safety_check": "safety_check"})
workflow.add_edge("tools", "chatbot")

def route_safety(state: AgentState):
    last_message = state["messages"][-1]
    if isinstance(last_message, HumanMessage) and last_message.name == "safety_guard":
        return "chatbot" # ë‹¤ì‹œ ìƒì„±í•´!
    return END

workflow.add_conditional_edges("safety_check", route_safety, {"chatbot": "chatbot", END: END})

app_graph = workflow.compile()

# =========================================================
# 5. ì™¸ë¶€ í˜¸ì¶œìš© Wrapper í•¨ìˆ˜
# =========================================================
def chat_with_nutritionist(user_profile: dict, recent_logs: list, chat_history: list):
    
    now_str = datetime.now().strftime("%Hì‹œ %Më¶„")
    
    # ë©”ì‹œì§€ ë³€í™˜ (Dict -> LangChain Message)
    lc_messages = []
    for msg in chat_history:
        if msg["role"] == "user": lc_messages.append(HumanMessage(content=msg["content"]))
        elif msg["role"] == "assistant": lc_messages.append(AIMessage(content=msg["content"]))
            
    # ìµœê·¼ ê¸°ë¡ ì£¼ì… (ë§ˆì§€ë§‰ ìœ ì € ë©”ì‹œì§€ì— ì»¨í…ìŠ¤íŠ¸ë¡œ ë¶™ì„)
    if recent_logs:
        log_text = "\n".join([f"- {l['time']} {l['desc']}" for l in recent_logs])
        if lc_messages and isinstance(lc_messages[-1], HumanMessage):
             lc_messages[-1].content += f"\n\n[ì°¸ê³ : ìµœê·¼ ì‹ì‚¬ ê¸°ë¡]\n{log_text}"
    
    inputs = {
        "messages": lc_messages,
        "user_profile": user_profile,
        "current_time": now_str
    }
    
    # ê·¸ë˜í”„ ì‹¤í–‰
    result = app_graph.invoke(inputs)
    return result["messages"][-1].content